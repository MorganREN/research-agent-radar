# src/research_agent/agents/scout/arxiv_scout.py
import arxiv
from src.research_agent.storage.models import Paper
from datetime import datetime
from loguru import logger

class ArxivScout:
    def __init__(self, query: str = "cat:cs.AI OR cat:cs.CE", max_results: int = 10):
        """
        query: arXivæŸ¥è¯¢è¯­æ³•ã€‚cs.CE ä»£è¡¨ Civil Engineering (åœŸæœ¨å·¥ç¨‹)
        """
        self.query = query
        self.max_results = max_results

    def fetch_papers(self) -> list[Paper]:
        logger.info(f"ğŸ•µï¸ Scout æ­£åœ¨ arXiv æœç´¢: {self.query} ...")
        
        # ä½¿ç”¨ arXiv å®¢æˆ·ç«¯æœç´¢
        client = arxiv.Client()
        search = arxiv.Search(
            query=self.query,
            max_results=self.max_results,
            sort_by=arxiv.SortCriterion.SubmittedDate # è·å–æœ€æ–°çš„
        )

        papers_found = []
        for result in client.results(search):
            # å°† arXiv åŸç”Ÿå¯¹è±¡è½¬æ¢ä¸ºæˆ‘ä»¬çš„æ•°æ®åº“æ¨¡å‹
            paper = Paper(
                id=f"arxiv:{result.entry_id.split('/')[-1]}", # æå– ID å¦‚ 2401.12345
                title=result.title,
                abstract=result.summary.replace("\n", " "),
                authors=[a.name for a in result.authors],
                url=result.pdf_url,
                published_date=result.published,
                source="arxiv",
                is_oa=True,  # arXiv ä¸Šçš„è®ºæ–‡éƒ½æ˜¯å¼€æ”¾è·å–çš„
                doi=result.doi if result.doi else None,  # æœ‰äº›è®ºæ–‡æ²¡æœ‰ DOI
                full_text_content=None  # arXiv ä¸å­˜å‚¨å…¨æ–‡æ–‡æœ¬
            )
            papers_found.append(paper)

        logger.success(f"âœ… Arxiv Scout æ‰¾åˆ°äº† {len(papers_found)} ç¯‡è®ºæ–‡ã€‚")
        return papers_found