# src/agents/analysis/reviewer.py
from openai import OpenAI
import os
from loguru import logger
from src.research_agent.storage.models import Paper
from src.research_agent.agents.analysis.parser import PDFParser
from dotenv import load_dotenv

load_dotenv() # åŠ è½½ .env ä¸­çš„ API KEY

class PaperReviewer:
    def __init__(self):
        self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.parser = PDFParser() # å¼•ç”¨ä¸Šé¢çš„è§£æå™¨

    def analyze_paper(self, paper: Paper, pdf_path: str=None, xml_content: str=None) -> str:
        # 1. è§£æ PDF æˆ– XML
        if xml_content and not pdf_path:  # ä½¿ç”¨ XML å†…å®¹ï¼ˆå¦‚æ¥è‡ª Elsevierï¼‰
            full_text = xml_content
        elif pdf_path and not xml_content:  # ä½¿ç”¨ PDF æ–‡ä»¶
            full_text = self.parser.parse_to_markdown(pdf_path)
        else:
            logger.error("å¿…é¡»æä¾› PDF è·¯å¾„æˆ– XML å†…å®¹è¿›è¡Œåˆ†æã€‚")
            return "è§£æå¤±è´¥ï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Šã€‚"
        if not full_text:
            return "è§£æå¤±è´¥ï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Šã€‚"

        print(f"ğŸ§  æ­£åœ¨æ·±åº¦é˜…è¯»è®ºæ–‡: {paper.title}...")

        # 2. åšå£«çº§åˆ†æ Prompt
        # è¿™é‡Œçš„ Prompt è®¾è®¡éå¸¸å…³é”®ï¼Œå¿…é¡»å¼ºåˆ¶ç»“æ„åŒ–è¾“å‡º
        system_prompt = """
        ä½ æ˜¯ä¸€ä½"äººå·¥æ™ºèƒ½+åœŸæœ¨å·¥ç¨‹"äº¤å‰é¢†åŸŸçš„èµ„æ·±å®¡ç¨¿äººã€‚
        ä½ çš„ä»»åŠ¡æ˜¯é˜…è¯»ä¸€ç¯‡å­¦æœ¯è®ºæ–‡ï¼Œå¹¶ä¸ºä¸€ä½æ­£åœ¨æ”»è¯»è¯¥é¢†åŸŸPhDçš„å­¦ç”Ÿæ’°å†™ä¸€ä»½æ·±åº¦åˆ†ææŠ¥å‘Šã€‚
        
        è¯·ä½¿ç”¨ Markdown æ ¼å¼ï¼Œä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ç»“æ„è¾“å‡ºæŠ¥å‘Šï¼š
        
        # 1. æ ¸å¿ƒè´¡çŒ® (Core Contribution)
        - ç”¨ä¸€å¥è¯æ¦‚æ‹¬æœ¬æ–‡è§£å†³çš„ç—›ç‚¹ã€‚
        - æœ¬æ–‡æå‡ºçš„æ ¸å¿ƒæ–¹æ³•/æ¨¡å‹æ˜¯ä»€ä¹ˆï¼Ÿï¼ˆå¦‚ä½¿ç”¨äº†ä»€ä¹ˆå…·ä½“çš„GNNå˜ä½“ã€Attentionæœºåˆ¶ç­‰ï¼‰
        
        # 2. æŠ€æœ¯æ‹†è§£ (Technical Implementation)
        - **æ•°æ®æ¥æº**: æ•°æ®é›†æ˜¯ä»€ä¹ˆï¼Ÿæ˜¯å¦å¼€æºï¼Ÿ
        - **è¾“å…¥è¾“å‡º**: æ¨¡å‹çš„è¾“å…¥ç‰¹å¾æ˜¯ä»€ä¹ˆï¼Ÿè¾“å‡ºç›®æ ‡æ˜¯ä»€ä¹ˆï¼Ÿ
        - **åŸºå‡†å¯¹æ¯”**: ç›¸æ¯” SOTA æ¨¡å‹æå‡äº†å¤šå°‘ï¼Ÿ
        
        # 3. åˆ›æ–°ç‚¹ä¸ç¼ºé™· (Strengths & Weaknesses)
        - âœ… **åˆ›æ–°ç‚¹**: (åˆ—å‡º2-3ç‚¹ï¼Œå¦‚ï¼šé¦–æ¬¡å°†XXç”¨äºéš§é“æ²‰é™é¢„æµ‹)
        - âš ï¸ **æ½œåœ¨ç¼ºé™·**: (åˆ—å‡º2-3ç‚¹ï¼Œå¦‚ï¼šå®éªŒæ•°æ®é‡ä¸è¶³ã€æ³›åŒ–èƒ½åŠ›å­˜ç–‘ã€æœªè€ƒè™‘å·¥ç¨‹åœ°è´¨å¤æ‚æ€§)
        
        # 4. å¯¹PhDç ”ç©¶çš„å¯ç¤º (Implications)
        - è¿™ç¯‡è®ºæ–‡çš„æ–¹æ³•è®ºæ˜¯å¦å¯ä»¥è¿ç§»åˆ°"éš§é“æ•°å­—å­ªç”Ÿ"æˆ–"å¤§å‹åŸºç¡€è®¾æ–½è¿ç»´"ä¸­ï¼Ÿ
        - å¦‚æœè¦å¤ç°ï¼Œæœ€å¤§çš„éš¾ç‚¹å¯èƒ½åœ¨å“ªé‡Œï¼Ÿ
        
        ---
        è¯·ä¿æŒè¯­æ°”å®¢è§‚ã€æ‰¹åˆ¤æ€§ï¼Œä¸è¦å•çº¯å¤è¿°æ‘˜è¦ã€‚
        """

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",  # å»ºè®®ä½¿ç”¨ GPT-4o ä»¥è·å¾—æœ€ä½³æ¨ç†èƒ½åŠ›
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"è®ºæ–‡æ ‡é¢˜: {paper.title}\n\nè®ºæ–‡å…¨æ–‡å†…å®¹:\n{full_text[:60000]}"} # æˆªå–å‰6wå­—ç¬¦é˜²æº¢å‡º
                ]
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"LLM åˆ†æå‡ºé”™: {e}"
        

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    from src.research_agent.storage.models import Paper, engine
    from sqlmodel import Session, select
    reviewer = PaperReviewer()
    with Session(engine) as session:
        statement = select(Paper).where(Paper.is_relevant == True).\
            where(Paper.download_status == "downloaded").\
            where(Paper.source == "arxiv")
        papers = session.exec(statement).all()
        if not papers:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å¾…åˆ†æçš„è®ºæ–‡ã€‚")
            exit(1)
        sample_paper = papers[0]  # å–ç¬¬ä¸€ä¸ªå¾…åˆ†æçš„è®ºæ–‡
    sample_pdf_path = f"data/papers/{sample_paper.id}.pdf".replace(":", "_")  # å‡è®¾ PDF æ–‡ä»¶åä¸è®ºæ–‡ ID ä¸€è‡´
    report = reviewer.analyze_paper(sample_paper, pdf_path=sample_pdf_path)
    print(report)