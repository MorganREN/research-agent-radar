import os
import requests
# from src.research_agents.acquisition.browser_engine import BrowserEngine

class DownloadManager:
    def __init__(self, storage_dir="data/papers"):
        self.storage_dir = storage_dir
        os.makedirs(self.storage_dir, exist_ok=True)
        # self.browser_engine = BrowserEngine()

    def _is_valid_pdf(self, file_path: str) -> bool:
        """ç®€å•çš„ PDF æ–‡ä»¶å¤´æ ¡éªŒ"""
        try:
            with open(file_path, "rb") as f:
                header = f.read(4)
                return header == b"%PDF"
        except:
            return False

    def download_arxiv_direct(self, url: str, save_path: str) -> bool:
        """ç­–ç•¥ A: arXiv ç›´æ¥ä¸‹è½½ (å¿«é€Ÿ)"""
        try:
            # å°† /abs/ æ›¿æ¢ä¸º /pdf/
            pdf_url = url.replace("/abs/", "/pdf/") + ".pdf"
            response = requests.get(pdf_url, timeout=30)
            if response.status_code == 200:
                with open(save_path, "wb") as f:
                    f.write(response.content)
                return True
            return False
        except Exception as e:
            print(f"Arxiv ä¸‹è½½é”™è¯¯: {e}")
            return False

    async def process_download(self, paper_id: str, url: str, source: str) -> str:
        """
        ä¸»å…¥å£ã€‚è¿”å›: 'downloaded', 'failed', 'login_required'
        """
        filename = f"{paper_id.replace(':', '_')}.pdf"
        save_path = os.path.join(self.storage_dir, filename)
        
        if os.path.exists(save_path):
            print(f"ğŸ“¦ æ–‡ä»¶å·²å­˜åœ¨: {filename}")
            return "downloaded"

        success = False
        
        # === è·¯ç”±é€»è¾‘ ===
        if "arxiv" in source.lower():
            print("ğŸš€ ä½¿ç”¨ HTTP ç›´æ¥ä¸‹è½½ç­–ç•¥ (Arxiv)")
            success = self.download_arxiv_direct(url, save_path)
        else:
            print("ğŸ•µï¸ ä½¿ç”¨ æµè§ˆå™¨ ä»¿çœŸä¸‹è½½ç­–ç•¥ (Auth/External)")
            # åªæœ‰é arXiv æ‰å¯åŠ¨æµè§ˆå™¨ï¼ŒèŠ‚çœèµ„æº
            # success = await self.browser_engine.download_pdf(url, save_path)

        # === ç»“æœæ ¡éªŒ ===
        if success and self._is_valid_pdf(save_path):
            return "downloaded"
        else:
            # ä¸‹è½½äº†ä½†ä¸æ˜¯PDFï¼ˆå¯èƒ½æ˜¯ç™»å½•é¡µæˆ–éªŒè¯ç é¡µï¼‰
            if os.path.exists(save_path): os.remove(save_path) 
            return "failed"
            

async def main():
    downloarder = DownloadManager()
    with Session(engine) as session:
        statement = select(Paper).where(Paper.is_relevant == True).\
            where(Paper.download_status == "pending")
        papers_to_download = session.exec(statement).all()
        logger.info(f"æ‰¾åˆ° {len(papers_to_download)} ç¯‡å¾…ä¸‹è½½è®ºæ–‡ã€‚")

        for paper in papers_to_download:
            logger.info(f"å¼€å§‹ä¸‹è½½è®ºæ–‡: {paper.id} ...")

            status = await downloarder.process_download(
                paper_id=paper.id,
                url=paper.url,
                source=paper.source
            )

            paper.download_status = status
            session.add(paper)
            session.commit()
    
            logger.info(f"è®ºæ–‡ {paper.id} ä¸‹è½½çŠ¶æ€: {status}")

if __name__ == "__main__":
    from src.research_agent.storage.models import Paper, engine
    from sqlmodel import Session, select
    from loguru import logger
    import asyncio
    
    asyncio.run(main())
    